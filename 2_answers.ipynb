{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"3-cnn-answ.ipynb","version":"0.3.2","provenance":[],"private_outputs":true,"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"eOsVdx6GGHmU"},"source":["Search for TODO."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ioLbtB3uGKPX","colab":{}},"source":["try:\n","  # %tensorflow_version only exists in Colab.\n","  %tensorflow_version 2.x\n","except Exception:\n","  pass\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"QS7DDTiZGRTo"},"source":["Import TensorFlow into your program:"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"0trJmd6DjqBZ","colab":{}},"source":["from __future__ import absolute_import, division, print_function, unicode_literals\n","\n","import tensorflow as tf\n","\n","from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPool2D\n","from tensorflow.keras import Model"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"7NAbSZiaoJ4z"},"source":["Load and prepare the [MNIST dataset](http://yann.lecun.com/exdb/mnist/)."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"JqFRS6K07jJs","colab":{}},"source":["mnist = tf.keras.datasets.mnist\n","\n","(x_train, y_train), (x_test, y_test) = mnist.load_data()\n","x_train, x_test = x_train / 255.0, x_test / 255.0\n","\n","# Add a channels dimension\n","x_train = x_train[..., tf.newaxis]\n","x_test = x_test[..., tf.newaxis]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"k1Evqx0S22r_"},"source":["Use `tf.data` to batch and shuffle the dataset:"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"8Iu_quO024c2","colab":{}},"source":["train_ds = tf.data.Dataset.from_tensor_slices(\n","    (x_train, y_train)).shuffle(10000).batch(32)\n","\n","test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"BPZ68wASog_I"},"source":["Build the `tf.keras` model using the Keras [model subclassing API](https://www.tensorflow.org/guide/keras#model_subclassing):"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"h3IKyzTCDNGo","colab":{}},"source":["########\n","# TODO: improve the model below\n","# - 1: Add a MaxPool2D layer in the constructor\n","# - https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/layers/MaxPool2D\n","# - 2: use it in the call method\n","# - 3: Create a deeper CNN if you like\n","########\n","\n","\n","class MyModel(Model):\n","  def __init__(self):\n","    super(MyModel, self).__init__()\n","    self.conv1 = Conv2D(32, 3, activation='relu', input_shape=(28,28,1))\n","    self.pool = MaxPool2D()\n","    self.flatten = Flatten()\n","    self.d1 = Dense(128, activation='relu')\n","    self.d2 = Dense(10, activation='softmax')\n","\n","  def call(self, x):\n","    x = self.conv1(x)\n","    x = self.pool(x)\n","    x = self.flatten(x)\n","    x = self.d1(x)\n","    return self.d2(x)\n","\n","# Create an instance of the model\n","model = MyModel()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"uGih-c2LgbJu"},"source":["Choose an optimizer and loss function for training: "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"u48C9WQ774n4","colab":{}},"source":["loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n","\n","optimizer = tf.keras.optimizers.Adam()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"JB6A1vcigsIe"},"source":["Select metrics to measure the loss and the accuracy of the model. These metrics accumulate the values over epochs and then print the overall result."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"N0MqHFb4F_qn","colab":{}},"source":["train_loss = tf.keras.metrics.Mean(name='train_loss')\n","train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n","\n","test_loss = tf.keras.metrics.Mean(name='test_loss')\n","test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"ix4mEL65on-w"},"source":["Use `tf.GradientTape` to train the model:"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"OZACiVqA8KQV","colab":{}},"source":["########\n","# TODO: your code here\n","# Wrap this function with a @tf.function to compile it\n","########\n","\n","@tf.function\n","def train_step(images, labels):\n","  with tf.GradientTape() as tape:\n","    predictions = model(images)\n","    loss = loss_object(labels, predictions)\n","  gradients = tape.gradient(loss, model.trainable_variables)\n","  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n","\n","  train_loss(loss)\n","  train_accuracy(labels, predictions)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Z8YT7UmFgpjV"},"source":["Test the model:"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"xIKdEzHAJGt7","colab":{}},"source":["#######\n","# TODO: your code here\n","# Likewise, you can use @tf.function here to speed this up\n","#######\n","\n","@tf.function\n","def test_step(images, labels):\n","  predictions = model(images)\n","  t_loss = loss_object(labels, predictions)\n","\n","  test_loss(t_loss)\n","  test_accuracy(labels, predictions)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"i-2pkctU_Ci7","colab":{}},"source":["EPOCHS = 5\n","\n","for epoch in range(EPOCHS):\n","  for images, labels in train_ds:\n","    train_step(images, labels)\n","\n","  for test_images, test_labels in test_ds:\n","    test_step(test_images, test_labels)\n","\n","  template = 'Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, Test Accuracy: {}'\n","  print(template.format(epoch+1,\n","                        train_loss.result(),\n","                        train_accuracy.result()*100,\n","                        test_loss.result(),\n","                        test_accuracy.result()*100))\n","\n","  # Reset the metrics for the next epoch\n","  train_loss.reset_states()\n","  train_accuracy.reset_states()\n","  test_loss.reset_states()\n","  test_accuracy.reset_states()"],"execution_count":0,"outputs":[]}]}