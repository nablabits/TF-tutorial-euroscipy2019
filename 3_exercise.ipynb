{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"2_deep_dream_exercise.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python2","display_name":"Python 2"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"WIRIzQTZcJv2","colab_type":"text"},"source":["A minimal example of gradient ascent. Search for TODO."]},{"cell_type":"code","metadata":{"id":"bqSuiPSbkQna","colab_type":"code","colab":{}},"source":["try:\n","  # %tensorflow_version only exists in Colab.\n","  %tensorflow_version 2.x\n","except Exception:\n","  pass"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3QCCKOi5k1WY","colab_type":"code","colab":{}},"source":["import numpy as np\n","import tensorflow as tf\n","\n","from IPython.display import clear_output\n","from matplotlib import pyplot as plt\n","from tensorflow.keras.preprocessing import image"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SxxgCLMFeQuq","colab_type":"text"},"source":["A few utilities for reading and preprocessing images."]},{"cell_type":"code","metadata":{"id":"17bCHfJXdQjz","colab_type":"code","colab":{}},"source":["# Download an image and read it into a NumPy array, \n","def download(url):\n","  name = url.split(\"/\")[-1]\n","  image_path = tf.keras.utils.get_file(name, origin=url)\n","  img = image.load_img(image_path)\n","  return image.img_to_array(img)\n","\n","# Scale pixels to between (-1.0 and 1.0)\n","def preprocess(img):\n","  return (img / 127.5) - 1\n","  \n","# Undo the preprocessing above\n","def deprocess(img):\n","  img = img.copy()\n","  img /= 2.\n","  img += 0.5\n","  img *= 255.\n","  return np.clip(img, 0, 255).astype('uint8')\n","\n","# Display an image\n","def show(img):\n","  plt.figure(figsize=(12,12))\n","  plt.grid(False)\n","  plt.axis('off')\n","  plt.imshow(img)\n","\n","url = 'https://upload.wikimedia.org/wikipedia/commons/thumb/c/c7/Bilbao_-_Guggenheim_aurore.jpg/800px-Bilbao_-_Guggenheim_aurore.jpg'\n","img = preprocess(download(url))\n","show(deprocess(img))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"d7f8UCVnjDko","colab_type":"text"},"source":["Build a feature extraction model using the [Keras Functional API](https://www.tensorflow.org/alpha/guide/keras/functional). It's pretty sweet!"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"PGmA_zG86gB4","colab":{}},"source":["inception_v3 = tf.keras.applications.InceptionV3(weights='imagenet',\n","                                                 include_top=False)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EXSURVuQxIJa","colab_type":"code","colab":{}},"source":["# We'll maximize the activations of these layers\n","names = ['mixed2', 'mixed3', 'mixed4', 'mixed5']\n","layers = [inception_v3.get_layer(name).output for name in names]\n","\n","# Create our feature extraction model\n","feat_extraction_model = tf.keras.Model(inputs=inception_v3.input, outputs=layers)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"I8uzM5OwCJai","colab_type":"text"},"source":["Here's our forward pass."]},{"cell_type":"code","metadata":{"id":"I3xAgaHE9Qv-","colab_type":"code","colab":{}},"source":["def forward(img):\n","  \n","  # Create a batch\n","  img_batch = tf.expand_dims(img, axis=0)\n","  \n","  # Forward the image through Inception, extract activations\n","  # for the layers we selected above\n","  return feat_extraction_model(img_batch)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cHT5Ve_F-M3v","colab_type":"text"},"source":["That's it for feature extraction. Now let's define our loss function. It'll be the mean activation of each of the layers we chose above."]},{"cell_type":"code","metadata":{"id":"q_Nrh8thxye5","colab_type":"code","colab":{}},"source":["def calc_loss(layer_activations):\n","  \n","  total_loss = 0\n","  \n","  for act in layer_activations:\n","    \n","    # In gradient ascent, we'll want to maximize this value\n","    # so our image increasingly \"excites\" the layer\n","    \n","    ##############\n","    # TODO\n","    # set the loss equal to the mean activation at this layer\n","    # loss = ...\n","    ########################\n","    loss = TODO\n","\n","    # Normalize by the number of units in the layer\n","    loss /= np.prod(act.shape)\n","    total_loss += loss\n","\n","  return total_loss"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tgapTtIx-QLk","colab_type":"text"},"source":["We can now run gradient ascent (this is similar to training a classifier, with a twist). We'll treat our input image as a weight matrix, and find the gradients of the loss with respect to it. Those gradients will have the same shape as the image (since there's one for each pixel) - so we can add them directly to the image to modify it. Rinse and repeat."]},{"cell_type":"code","metadata":{"id":"Jq11UtV1uMnn","colab_type":"code","colab":{}},"source":["# Convert our image into a variable for training\n","img = tf.Variable(img)\n","\n","# Run a few iterations of gradient ascent\n","steps = 400\n","\n","for step in range(steps):\n","  \n","  with tf.GradientTape() as tape:    \n","    activations = forward(img)\n","    loss = calc_loss(activations)\n","    \n","  # How cool is this? It's the gradient of the \n","  # loss (how excited the layer is) with respect to the\n","  # pixels of our random image!\n","  \n","  ##############\n","  ## TODO: your code here\n","  ## Calculate the gradients of the loss w.r.t. the image\n","  ## See: http://bit.ly/tf-ws1\n","  ## gradients = tape.gradient ...\n","  ##############\n","  gradients = TODO\n","\n","  # Normalize the gradients\n","  gradients /= gradients.numpy().std() + 1e-8 \n","  \n","  # Update our image by directly adding the gradients\n","  # (because they're the same shape!)\n","  \n","  ##############\n","  # TODO\n","  # Add the gradients to the variable\n","  # Normally, you do not need to write code at this low of a level\n","  # See https://www.tensorflow.org/beta/guide/variables\n","  # img.assign...(gradients)\n","  ##############\n","  img.TODO\n","  \n","  if step % 50 == 0:\n","    clear_output()\n","    print (\"Step %d, loss %f\" % (step, loss))\n","    show(deprocess(img.numpy()))\n","    plt.show()\n","\n","# Let's see the result\n","# Notice we're calling .numpy() here, which \n","# takes us from TensorFlow land -> NumPy land\n","clear_output()\n","show(deprocess(img.numpy()))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"v3fAjeKYckyd","colab_type":"text"},"source":["That's it! For the bells and whistles (there are many) you can explore this full [implementation](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/tutorials/deepdream) in TensorFlow v1 (perfect for concepts, but you'll probably want to adapt the code to something more modern), and this helpful [notebook](https://github.com/fchollet/deep-learning-with-python-notebooks/blob/master/8.2-deep-dream.ipynb) from Deep Learning with Python using the Keras reference implementation.\n","\n","*Update*: we added a faster implementation in TF 2.0 here: https://www.tensorflow.org/beta/tutorials/generative/deepdream"]}]}